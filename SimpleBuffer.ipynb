{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cython and the Buffer Protocol for loading binary data\n",
    "\n",
    "There are times when you need to load binary data into NumPy / Pandas but the data format is either binary or some irregularly structured ASCII data and you __don't__ already have a good reader for the format.  Today, I'm going to show you some simple code you can use to do the loading and get back to analysis!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Formats\n",
    "\n",
    "We're going to focus on loading binary data that is stored in a record format that's similar to the diagram below.  This is just for the purposes of demonstration, though.  All the code we'll develop here can be easily modified to fit whatever binary format your data is in.  You could even use these same methods to efficiently load irregularly structured text data.\n",
    "\n",
    "For demonstration purposes we'll consider binary data where each record is laid out something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/SampleBinaryLayout.png \"Sample Binary Layout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest Case:  All records have an identical, fixed length format\n",
    "\n",
    "This is the simplest case.  Let's say our binary data has the layout above but where the file contains only a single record type which consists of:\n",
    "\n",
    "* 4 byte header ( as defined above )\n",
    "* 9 bytes total in the message body\n",
    "    * First 4 bytes encode an usigned int ( [little endian](https://en.wikipedia.org/wiki/Endianness) byte ordering )\n",
    "    * Next 5 bytes encode a character array\n",
    "\n",
    "Ultimately, we want to get our data into a Pandas DataFrame, and to do this we're going to first load our data to a NumPy array.  Once we have a NumPy array, it's just a one liner to create the Pandas DataFrame.  \n",
    "\n",
    "The only tricky part here is that NumPy arrays are homogeneous meaning that all the elements in the array have to be of the same type.  Fortunately, however, NumPy lets us define structured types where the dtype contains a bunch of separate components.  So what we'll do next is construct a NumPy dtype which has the same structure as our binary records.  If you want to read the docs you can do that [here](https://NumPy.org/devdocs/reference/arrays.dtypes.html) but specifying the NumPy dtype is really pretty simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# define a np.dtype that matches our binary record layout\n",
    "dt = np.dtype([\n",
    "    ('body_length', '<u2'),   # two byte unsigned integer (little endian)\n",
    "    ('msg_type', '<u2'),      \n",
    "    ('number', '<i4'),        # four byte signed integer (little endian) \n",
    "    ('name', 'S5')            # 5 byte character array\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the companion notebook WorkingWithBytes, I already setup a binary file with the format above.  So now, with the NumPy.dtype defined we can go from binary data to Pandas dataframe in just a few lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'one'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b'two'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>b'three'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  number      name\n",
       "0            9         1       1    b'one'\n",
       "1            9         1       2    b'two'\n",
       "2            9         1       3  b'three'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/simple_binary.bin', 'rb') as f:\n",
    "    b = f.read()                 # read in the binary file as bytes\n",
    "    \n",
    "np_data = np.frombuffer(b, dt)   # creates a NumPy array\n",
    "df = pd.DataFrame(np_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couldn't be easier right?  One little thing to take care of, however, is that the 'name' column in our data is holding objects of type 'byte'.  We'd probably rather have strings so let's use the Series.str.decode() method to do the conversion from bytes to a Python string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  number   name\n",
       "0            9         1       1    one\n",
       "1            9         1       2    two\n",
       "2            9         1       3  three"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'] = df['name'].str.decode('utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about binary data with multiple record types?\n",
    "\n",
    "Loading the binary data above was super easy but unfortunately, binary data is usually not structured so nicely.  Typically there are many different record types all mixed together in a single file and we need a way to load these into one or more dataframes.  \n",
    "\n",
    "The challenge here is that NumPy only knows how to load binary data that is stored in a 'simple' format where the data exists in a contiguous block of memory consisting of identical records stacked back to back.  In the example above, our data had only a single fixed-length record type, and that made it very easy to load.\n",
    "\n",
    "In general however, in order to load binary data to NumPy, we'll need to split it into one or more homogeneous arrays as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/CollateMultipleRecords.png \"Collate multiple records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do the split above is to write some preprocessing code (pick any language you want!) to split the binary data into one or more files.  If you go that route then you can simply do your preprocessing and then load the individual files like we did above.  The downside to this approach is that the preprocessing will create multiple copies of your data on disk which isn't very elegant and could potentially be a hassle.   \n",
    "\n",
    "So instead of writing out separate files, we'll show how to setup memory arrays in Cython, one for each record type that we're interested in, and efficiently fill them with our binary records.  We'll then expose these arrays to NumPy by using the buffer protocol from the Python C-API.  We could do all of this in native Python, but we'll use Cython because we want our solution to be fast (binary files are sometimes quite large).  There's quite a bit here, but it turns out you can do a lot with just a little bit of code so let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python C-API and the Buffer Protocol\n",
    "\n",
    "The Python C-API is the doorway into a lower level implementation of Python.  It allows programmers to extend Python with code written in C/C++ and also lets you embed Python into other programming languages.  We won't need to know much about the C-API though.  All we need is a high level understanding of the buffer protocol.\n",
    "\n",
    "The buffer protocol operates at the C-API level and defines a way that Python objects can access and share each others memory.  When we call NumPy.frombuffer on an object that implements the buffer protocol, NumPy goes down into the C-API and asks the object for a view of its internal memory.  If successful, NumPy goes on to setup an array using the shared data.  Note that there is no copying going on here!  After the call to NumPy.frombuffer, both the original buffer object and the NumPy array are sharing the same underlying memory.  A simplified version of the process looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/BufferProtocolUsage.png \"Buffer Protocol Diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than use the C-API directly, however, we're going to interact with the C-API via Cython because it's a lot easier than writing code directly in C/C++.  It's pretty simple to implement the buffer protocol from Cython but first, lets do a quick Hello World in Cython to make sure everythings setup right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython:  Hello World\n",
    "\n",
    "Cython is an extension to Python which is a combination of Python and C/C++.  Code compiled from Cython often runs much faster than native Python and gives you the ability to use functions and classes from C/C++ libraries.  The process happens in two stages\n",
    "\n",
    "1.  Write some Cython code and compile it to C/C++ with Cython\n",
    "2.  Compile the C/C++ code to create a Python module that you can import\n",
    "\n",
    "In iPython, these steps can be combined and simplified by using some iPython magic.  Let's try it out with a simple 'Hello World' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cython is included in many common Python distributions but if not you'll need to \n",
    "# do a '!pip install Cython'.  As always, it's best to use a dedicated virtual environment.\n",
    "# but here we'll assume that Cython is already installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the magic Cython extension\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus\n",
    "\n",
    "# The magic %%Cython command above has to be the first thing.  Evaluating this cell\n",
    "# will compile this Cython -> C++, then compile the C++, and finally import the \n",
    "# HelloWorldBuffer class to our iPython session\n",
    "cdef class HelloWorldBuffer:\n",
    "    def __cinit__(self, b):\n",
    "        print(\"I was initialized with '{}'\".format(b))\n",
    "        \n",
    "    def say_something(self):\n",
    "        print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was initialized with 'hi'\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# Let's try it\n",
    "h = HelloWorldBuffer('hi')    # should print \"I was initialized with 'hi'\"\n",
    "h.say_something()             # should print \"hello world\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So hopefully the above cell worked for you.  Now let's create a more usefull class that implements the buffer protocol!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython:  implement the buffer protocol\n",
    "\n",
    "Our first goal here is to setup a Python object that implements the buffer protocol.  Once we've done that, we'll go back and write a little bit of extra code to create multiple buffer objects and fill them with records from the binary file.\n",
    "\n",
    "Implementing the buffer protocol from Cython just requires us to implement two methods \\_\\_getbuffer__ and \\_\\_releasebuffer__.  Behind the scenes, Cython has some special handling of these so that they get correctly tied to our object in the C-API but we don't need to worry about that;  all we need to do is implement the two methods and they're both pretty simple for us.  Here's what they do:\n",
    "\n",
    "**\\_\\_getbuffer__(self, Py_buffer *, int)**  This method will be called by any consumer object that wants a view of our memory.  It has two arguments: an integer of bit flags, and a pointer to a simple C struct Py_buffer.  The flags indicate details about the data format that the consumer is expecting.  In our case, we'll support just the simplest type which is one dimensional data stored in a contigous block of memory.  So all we have to do in \\_\\_getbuffer__ is check that the flags indicate a simple buffer, and then fill in a few fields in the Py_buffer struct.  In our case these fields are all self-explanatory ( see below ).\n",
    "\n",
    "**\\_\\_releasebuffer__(self, Py_buffer *)**  The purpose of \\_\\_releasebuffer__ is to allow reference counting so that our code knows when it can release and/or reallocate memory in the Py_buffer structure.  NumPy, however, doesn't respect this and expects that buffers maintain their data even after calls to \\_\\_releasebuffer__.  Because of this we don't need to do anything with the \\_\\_releasebuffer__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus\n",
    "# or optionally %%Cython --cplus --annotate which will show information about how\n",
    "# the code is compiled to C/C++ binary\n",
    "\n",
    "from cpython cimport Py_buffer\n",
    "from cpython.buffer cimport PyBUF_SIMPLE, PyBUF_WRITEABLE\n",
    "from libcpp.vector cimport vector\n",
    "from libc.stdint cimport uint8_t\n",
    "from libc.string cimport memcpy\n",
    "\n",
    "\n",
    "cdef class SimplestBuffer:\n",
    "    cdef:\n",
    "        vector[uint8_t] buf   # We're using vector from C++ to manage memory allocation\n",
    "     \n",
    "    # in Cython, methods defined with 'def' are slower but accessible from Python\n",
    "    # extend will add bytes to our internal memory\n",
    "    def extend(self, input_bytes):\n",
    "        self.add_bytes(input_bytes, len(input_bytes))   \n",
    "    \n",
    "    # methods defined with 'cdef' may be faster but are accessible only from Cython\n",
    "    cdef add_bytes(self, char *b, int num_bytes):  \n",
    "        cdef int curr_size = self.buf.size()\n",
    "        self.buf.resize(curr_size + num_bytes)                     # resize vector if necessary\n",
    "        memcpy(&(self.buf[curr_size]), <uint8_t *>b, num_bytes)    # copy bytes into self.buf\n",
    "    \n",
    "    def __getbuffer__(self, Py_buffer *buffer, int flags):\n",
    "        # if the requested buffer type is not PyBUF_SIMPLE then error out\n",
    "        # we will allow either readonly or writeable buffers however\n",
    "        if flags != PyBUF_SIMPLE and flags != PyBUF_SIMPLE | PyBUF_WRITEABLE:\n",
    "            raise BufferError\n",
    "            \n",
    "        buffer.buf = <char *>&(self.buf[0])  # points to our buffer memory\n",
    "        buffer.format = NULL                 # NULL format means bytes \n",
    "        buffer.internal = NULL               # this is for our own use if needed\n",
    "        buffer.itemsize = 1                     \n",
    "        buffer.len = self.buf.size()\n",
    "        buffer.ndim = 1\n",
    "        buffer.obj = self\n",
    "        buffer.readonly = not (flags & PyBUF_WRITEABLE)\n",
    "        buffer.shape = NULL                  # none of shapes, strides or suboffsets are used for PyBUF_SIMPLE\n",
    "        buffer.strides = NULL\n",
    "        buffer.suboffsets = NULL    \n",
    "\n",
    "    # the buffer protocol requires this method\n",
    "    def __releasebuffer__(self, Py_buffer *buffer):\n",
    "        pass       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out!  All we need to do is create one of these SimplestBuffer objects, fill it with some byte data and then use np.frombuffer() just like we did earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'one'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b'two'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>b'three'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  number      name\n",
       "0            9         1       1    b'one'\n",
       "1            9         1       2    b'two'\n",
       "2            9         1       3  b'three'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/simple_binary.bin', 'rb') as f:\n",
    "    b = f.read() \n",
    "    \n",
    "sb = SimplestBuffer() \n",
    "sb.extend(b)  # we implemented this method above.  it fills the buffer with the bytes b   \n",
    "df = pd.DataFrame(np.frombuffer(sb, dt))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if you made it this far, congradulations!!!  The hard part is done.  Now all we need to do is write a little more code to take binary data with mixed record types, and fan the data out to multiple buffers.  Note that while SimplestBuffer is a fairly generic reusable class, this next bit of code in the function fan_bytes should be specialized to the exact format of **your** binary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus\n",
    "# or optionally %%Cython --cplus --annotate which will show information about how\n",
    "# the code is compiled to C/C++ binary\n",
    "\n",
    "from cpython cimport Py_buffer\n",
    "from cpython.buffer cimport PyBUF_SIMPLE, PyBUF_WRITEABLE\n",
    "from libcpp.vector cimport vector\n",
    "from libc.stdint cimport uint8_t, uint16_t\n",
    "from libc.string cimport memcpy, strlen\n",
    "from cython.operator cimport dereference as deref\n",
    "\n",
    "# this is the same as the class above but we need to repeat it here\n",
    "cdef class SimplestBuffer:\n",
    "    cdef:\n",
    "        vector[uint8_t] buf   # We're using vector from C++ to manage memory allocation\n",
    "     \n",
    "    # in Cython, methods defined with 'def' are slower but accessible from Python\n",
    "    # extend will add bytes to our internal memory\n",
    "    def extend(self, input_bytes):\n",
    "        self.add_bytes(input_bytes, len(input_bytes))   \n",
    "    \n",
    "    # methods defined with 'cdef' may be faster but are accessible only from Cython\n",
    "    cdef add_bytes(self, char *b, int num_bytes):  \n",
    "        cdef int curr_size = self.buf.size()\n",
    "        self.buf.resize(curr_size + num_bytes)                     # resize vector if necessary\n",
    "        memcpy(&(self.buf[curr_size]), <uint8_t *>b, num_bytes)    # copy bytes into self.buf\n",
    "    \n",
    "    def __getbuffer__(self, Py_buffer *buffer, int flags):\n",
    "        # if the requested buffer type is not PyBUF_SIMPLE then error out\n",
    "        # we will allow either readonly or writeable buffers however\n",
    "        if flags != PyBUF_SIMPLE and flags != PyBUF_SIMPLE | PyBUF_WRITEABLE:\n",
    "            raise BufferError\n",
    "            \n",
    "        buffer.buf = <char *>&(self.buf[0])  # points to our buffer memory\n",
    "        buffer.format = NULL                 # NULL format means bytes \n",
    "        buffer.internal = NULL               # this is for our own use if needed\n",
    "        buffer.itemsize = 1                     \n",
    "        buffer.len = self.buf.size()\n",
    "        buffer.ndim = 1\n",
    "        buffer.obj = self\n",
    "        buffer.readonly = not (flags & PyBUF_WRITEABLE)\n",
    "        buffer.shape = NULL                  # none of shapes, strides or offsets are used for PyBUF_SIMPLE\n",
    "        buffer.strides = NULL\n",
    "        buffer.suboffsets = NULL    \n",
    "\n",
    "    # the buffer protocol requires this method\n",
    "    def __releasebuffer__(self, Py_buffer *buffer):\n",
    "        pass   \n",
    "\n",
    "# this function walks through the input_bytes and copies each record into one \n",
    "# or the other of the buffers.  ( depending on the value of msg_type )\n",
    "def fan_bytes(bytes input_bytes, SimplestBuffer buf1, SimplestBuffer buf2):\n",
    "    cdef int num_bytes = len(input_bytes)\n",
    "    cdef char *b = <char *>input_bytes                # you can cast bytes objects to char *\n",
    "    cdef int cursor = 0\n",
    "    cdef uint16_t msg_type\n",
    "    cdef uint16_t body_len\n",
    "    \n",
    "    # here we step through the character array by doing some C/C++ pointer arithmetic...\n",
    "    while cursor < num_bytes:\n",
    "        body_len = deref(<uint16_t*>(b + cursor)) \n",
    "        msg_type = deref(<uint16_t*>(b + cursor + 2))\n",
    "        \n",
    "        # copy bytes into either buf1 or buf2 depending on msg_type.  \n",
    "        if msg_type == 1:\n",
    "            buf1.add_bytes(b + cursor, body_len + 4)  # body_len + 4 is our record length incl. the 4 byte header\n",
    "        elif msg_type == 2:\n",
    "            buf2.add_bytes(b + cursor, body_len + 4)\n",
    "            \n",
    "        cursor += body_len + 4                        # advance cursor forward to beginning of next record \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fan_bytes function above is specialized to handle binary data with the example structure that we illustrated earlier.  That is, all records have a 4 byte header where the first two bytes tell the length ( in bytes ) of the message body and the second two bytes encode a 'message type' which labels how to decode the message body into a set of data fields.  To decode your binary data, you'll need to look up the reference documentation for your binary format and modify fan_bytes as appropriate.  Note that in this example, the fan_bytes function doesn't need to know anything about the structure of the message body; all it does is copy bytes from the binary record onto one of our buffer objects.\n",
    "\n",
    "So let's see it in action!  Here we'll use SimplestBuffer and fan_bytes together to decode a binary file that a mix of two different record types.  The data was setup in the notebook WorkingWithBytes and is similar to our previous binary data except now we have mixed in a second record type which has the same header but the body of the message consists of 4 consecutive 32 bit integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'one'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b'two'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>b'three'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  number      name\n",
       "0            9         1       1    b'one'\n",
       "1            9         1       2    b'two'\n",
       "2            9         1       3  b'three'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  a  b  c   d\n",
       "0           16         2  1  2  3   4\n",
       "1           16         2  2  4  6   8\n",
       "2           16         2  3  6  9  12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/simple_binary_mixed.bin', 'rb') as f:\n",
    "    b = f.read()\n",
    "\n",
    "# create two buffers and use the helper function above to fill them\n",
    "sb1 = SimplestBuffer()\n",
    "sb2 = SimplestBuffer()\n",
    "fan_bytes(b, sb1, sb2)\n",
    "\n",
    "# dt1 is the same dtype we used before.  dt2 specifies a 20 byte record:  same header followed by four 32 bit integers\n",
    "dt1 = np.dtype([('body_length', '<i2'), ('msg_type', '<i2'), ('number', '<u4'), ('name', 'S5')])\n",
    "dt2 = np.dtype([('body_length', '<i2'), ('msg_type', '<i2'), ('a', '<i4'), ('b', '<i4'), ('c', '<i4'), ('d', '<i4')])\n",
    "\n",
    "# fan_bytes already loaded up the SimplestBuffer objects so now we just convert these to dataframes\n",
    "df1 = pd.DataFrame(np.frombuffer(sb1, dt1))\n",
    "df2 = pd.DataFrame(np.frombuffer(sb2, dt2))\n",
    "\n",
    "# and display them!\n",
    "from IPython.display import display\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's progress!!!  At this point we've successfully loaded a binary file containing mixed record types into two dataframes, one for each record type.  Before wrapping up, however, there's a few improvements that are worth making.  \n",
    "\n",
    "First we need to improve the memory safety of SimplestBuffer so that the underlying memory can't get reallocated while NumPy or Pandas is sharing the memory.  In the buffer protocol, this is supposed to be done by doing reference counting based on calls to getbuffer and releasebuffer and we implement this below.  See comments in the code for more details.  \n",
    "\n",
    "Secondly we're also adding the ability to preallocate memory on the buffer and read bytes directly from a file as optional abilities.  Note however, that vector already does a decent job with being efficient about reallocating memory ( ie, it will reserve successively larger and larger blocks of memory rather than reallocate every time you want to extend the vector by a few bytes ).  And with regard to reading from files, it's often faster to read all the binary data into an intermediate buffer before processing rather than making many small reads on the file system.  Nevertheless, both of these can lead to speedups so we include them in our SimpleBuffer implementation here.\n",
    "\n",
    "And finally, it's often useful to create loadable modules from Cython rather than putting all of your Cython into Jupyter notebooks.  So in the cells below, rather than use the %%Cython magic as we did above, we're going to output the Cython code to a file and use setuptools to create a loadable module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting binbuffer.pyx\n"
     ]
    }
   ],
   "source": [
    "%%writefile binbuffer.pyx\n",
    "\n",
    "# the next line is not just a comment, it tells Cython to build C++ code\n",
    "# distutils: language = c++\n",
    "\n",
    "from cpython cimport Py_buffer\n",
    "from cpython.buffer cimport PyBUF_SIMPLE, PyBUF_WRITEABLE\n",
    "from libcpp.vector cimport vector\n",
    "from libcpp cimport bool\n",
    "from libc.stdio cimport FILE, fread, fopen, fclose, fseek, SEEK_CUR\n",
    "from libc.stdint cimport uint8_t, uint16_t\n",
    "from libc.string cimport memcpy\n",
    "from cython.operator cimport dereference\n",
    "\n",
    "\"\"\"\n",
    "Here is our generic SimplestBuffer reimplemented with:\n",
    "\n",
    "1) access restrictions ( no reallocating memory if the buffer has ever been accessed )\n",
    "2) ability to preallocate memory if desired ( for some small speed gains )\n",
    "3) method to read bytes directly from a file\n",
    "\n",
    "NOTE:  If you examine SimpleBuffer below, you'll see that the view_count and buffer_accessed are somewhat redundant\n",
    "and you could actually remove view_count entirerly without changing any functionality.  We've included\n",
    "view_count for illustration purposes however, because it shows how reference counting is supposed to work\n",
    "with the buffer protocol:  ie, if there are any open views on the buffer, then the buffer memory should not be changed\n",
    "because other objects are referencing it.  Unfortunately, NumPy currently doesn't respect this protocol\n",
    "and expects buffers to exist and be unchanged even after calls to releasebuffer.  For this reason, we added the bool\n",
    "buffer_accessed to prevent any reallocation of buffer memory once a view on the memory has been requested\n",
    "via getbuffer.\n",
    "\n",
    "\"\"\"\n",
    "cdef class SimpleBuffer:\n",
    "    cdef: \n",
    "        vector[uint8_t] buf   # vector is useful here.  We get a contiguous block of memory but don't have to manage memory ourselves.\n",
    "        unsigned int cursor            # keep track of where to put next elements in buf\n",
    "        int view_count        # reference counting for open views\n",
    "        bool buffer_accessed  # we need this because NumPy expects buffers to exist even after releasebuffer\n",
    "\n",
    "    def __cinit__(self):\n",
    "        self.view_count = 0   \n",
    "        self.cursor = 0\n",
    "        self.buffer_accessed = False  \n",
    "        \n",
    "    def extend(self, b):\n",
    "        self.add_bytes(b, len(b))\n",
    "    \n",
    "    # we split out this method so that we can preallocate if we want.  \n",
    "    cdef maybe_allocate(self, unsigned int n):\n",
    "        if self.buffer_accessed or self.view_count > 0:\n",
    "            raise RuntimeError('Buffer has been locked to changes in size')\n",
    "        if self.buf.size() < self.cursor + n:\n",
    "            self.buf.resize(self.cursor + n)\n",
    "        \n",
    "    cdef add_bytes(self, char *b, unsigned int n):\n",
    "        self.maybe_allocate(n)  \n",
    "        memcpy(&(self.buf[self.cursor]), b, n)\n",
    "        self.cursor += n\n",
    "        \n",
    "    cdef add_bytes_from_file(self, FILE *fp, unsigned int n):\n",
    "        self.maybe_allocate(n)\n",
    "        fread(&(self.buf[self.cursor]), 1, n, fp)\n",
    "        self.cursor += n\n",
    "            \n",
    "    def __getbuffer__(self, Py_buffer *buffer, int flags):\n",
    "        if flags != PyBUF_SIMPLE and flags != PyBUF_SIMPLE | PyBUF_WRITEABLE:\n",
    "            raise BufferError\n",
    "            \n",
    "        buffer.buf = <char *>&(self.buf[0])\n",
    "        buffer.format = NULL                    # NULL format means bytes \n",
    "        buffer.internal = NULL                  # see References\n",
    "        buffer.itemsize = 1\n",
    "        buffer.len = self.buf.size()\n",
    "        buffer.ndim = 1\n",
    "        buffer.obj = self\n",
    "        buffer.readonly = not (flags & PyBUF_WRITEABLE)\n",
    "        buffer.shape = NULL\n",
    "        buffer.strides = NULL\n",
    "        buffer.suboffsets = NULL    \n",
    "        \n",
    "        self.view_count += 1\n",
    "        self.buffer_accessed = True\n",
    "\n",
    "    def __releasebuffer__(self, Py_buffer *buffer):\n",
    "        self.view_count -= 1  \n",
    "        \n",
    "\n",
    "def fan_bytes(bytes input_bytes, SimpleBuffer buf1, SimpleBuffer buf2):\n",
    "    cdef int num_bytes = len(input_bytes)\n",
    "    cdef char *b = <char *>input_bytes  # you can cast bytes objects to char *\n",
    "    cdef int cursor = 0\n",
    "    cdef uint16_t msg_type\n",
    "    cdef uint16_t msg_len\n",
    "    \n",
    "    # here we step through the character array by doing some C/C++ pointer arithmetic\n",
    "    while cursor < num_bytes:\n",
    "        body_len = dereference(<uint16_t*>(b + cursor)) \n",
    "        msg_type = dereference(<uint16_t*>(b + cursor + 2))\n",
    "        \n",
    "        if msg_type == 1:\n",
    "            buf1.add_bytes(b + cursor, body_len + 4)  # msg_len + 4 is our total record length including the 4 byte header\n",
    "        elif msg_type == 2:\n",
    "            buf2.add_bytes(b + cursor, body_len + 4)\n",
    "            \n",
    "        cursor += body_len + 4\n",
    "\n",
    "\n",
    "def fan_binary_file(bytes filename, SimpleBuffer buf1, SimpleBuffer buf2):\n",
    "    cdef uint16_t header[2]\n",
    "    cdef FILE *fp = fopen(filename, \"r\")\n",
    "    while fread(header, 1, 4, fp) == 4:\n",
    "        if header[1] == 1:\n",
    "            buf1.add_bytes(<char *>header, 4)\n",
    "            buf1.add_bytes_from_file(fp, header[0])\n",
    "        elif header[1] == 2:\n",
    "            buf2.add_bytes(<char *>header, 4)\n",
    "            buf2.add_bytes_from_file(fp, header[0])\n",
    "        else:\n",
    "            fseek(fp, header[0], SEEK_CUR)\n",
    "    \n",
    "    fclose(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell wrote the Cython code to the file 'binbuffer.pyx'  This next cell writes a file 'setup.py' that we'll need for compiling and installing the Cython using setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "from setuptools import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(\n",
    "    name='binbuffer',\n",
    "    ext_modules=cythonize('binbuffer.pyx', language_level=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling binbuffer.pyx because it changed.\n",
      "[1/1] Cythonizing binbuffer.pyx\n",
      "running build_ext\n",
      "building 'binbuffer' extension\n",
      "gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/anaconda3/include -arch x86_64 -I/opt/anaconda3/include -arch x86_64 -I/opt/anaconda3/include/python3.7m -c binbuffer.cpp -o build/temp.macosx-10.9-x86_64-3.7/binbuffer.o\n",
      "g++ -bundle -undefined dynamic_lookup -L/opt/anaconda3/lib -arch x86_64 -L/opt/anaconda3/lib -arch x86_64 -arch x86_64 build/temp.macosx-10.9-x86_64-3.7/binbuffer.o -o build/lib.macosx-10.9-x86_64-3.7/binbuffer.cpython-37m-darwin.so\n",
      "copying build/lib.macosx-10.9-x86_64-3.7/binbuffer.cpython-37m-darwin.so -> \n"
     ]
    }
   ],
   "source": [
    "# and now compile and install the binary in the local directory\n",
    "!Python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can import the binbuffer module that we built above\n",
    "from binbuffer import SimpleBuffer, fan_bytes, fan_binary_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>number</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b'one'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b'two'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>b'three'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  number      name\n",
       "0            9         1       1    b'one'\n",
       "1            9         1       2    b'two'\n",
       "2            9         1       3  b'three'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  msg_type  a  b  c   d\n",
       "0           16         2  1  2  3   4\n",
       "1           16         2  2  4  6   8\n",
       "2           16         2  3  6  9  12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "with open('data/simple_binary_mixed.bin', 'rb') as f:\n",
    "    b = f.read()\n",
    "\n",
    "# create two buffers and use the helper function above to fill them\n",
    "sb1 = SimpleBuffer()\n",
    "sb2 = SimpleBuffer()\n",
    "fan_bytes(b, sb1, sb2)\n",
    "\n",
    "# alternately, instead of using fan_bytes, here's an example that loads the buffers directly from the binary file\n",
    "#fan_binary_file(b'simple_binary_mixed.bin', sb1, sb2)  \n",
    "\n",
    "# dt1 is the same dtype we used before.  dt2 specifies a 20 byte record:  same header followed by four 32 bit integers\n",
    "dt1 = np.dtype([('body_length', '<i2'), ('msg_type', '<i2'), ('number', '<u4'), ('name', 'S5')])\n",
    "dt2 = np.dtype([('body_length', '<i2'), ('msg_type', '<i2'), ('a', '<i4'), ('b', '<i4'), ('c', '<i4'), ('d', '<i4')])\n",
    "\n",
    "# fan_bytes ( or fan_binary_file ) already loaded up the SimplestBuffer objects so now we just convert these to dataframes\n",
    "df1 = pd.DataFrame(np.frombuffer(sb1, dt1))\n",
    "df2 = pd.DataFrame(np.frombuffer(sb2, dt2))\n",
    "\n",
    "# and display them!\n",
    "from IPython.display import display\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Remarks\n",
    "\n",
    "I hope you've found this notebook useful and that it helps you to load your binary data and get back to analysis!!!  Before leaving, I want to add just a few more remarks.\n",
    "\n",
    "**Evaluation Speed**:  We didn't do any benchmarking here, but in my tests, I've generally found that loading binary data using the above methods is about as fast as loading equivalent dataframes from pickled binaries (sometimes it's even faster!).  So the code runs quite fast.  One area that is not fast however, is the conversion of byte arrays to strings ( using Pandas.Series.str.decode('utf-8') ).  In my experience this conversion is often the slowest part of loading binary data.  If this conversion is causing you headaches, you can consider just leaving some or all of your character data as byte arrays rather than native string objects.  Also, In Pandas 1.0, a new string type has been introduced but it's still experimental.  Perhaps something there can make the conversion faster.\n",
    "\n",
    "**Variable Record Lengths**:  In the examples here, our record types all had fixed lengths but in the wild, binary records often have variable lengths due either to the presence of variable length character arrays, or repeating groups within the record.  In order to handle records of this type, you'll have to truncate the character arrays to some maximum length and find a way to deal with any repeating groups.  The general tools above are all you really need however, so just beware that this is something you may have to deal with and you'll have no problems coming up with some solution that works for you in your situation.\n",
    "\n",
    "**Irregularly Structured ASCII data**:  In this article, we focused on binary data, but I just want to note quickly, that if you have large quantities of irregularly structured ASCII data, you can use the same techniques here to efficiently process and load your data.  Again, just figure out a final structure that works as a dataframe, and then write some Cython to parse your ascii file into one or more buffers as we did above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
